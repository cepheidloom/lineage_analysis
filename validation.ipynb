{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a594dd",
   "metadata": {},
   "source": [
    "### Create set of all object present in json files inside dedicated folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e758f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "folder = \"../lineage_outputs/\"\n",
    "json_list = []\n",
    "error_json_reading = dict()\n",
    "for file in os.listdir(folder):\n",
    "    with open(folder+file, \"r\") as f:\n",
    "        json_file = json.load(f)\n",
    "        json_file[\"file_name\"] = file.replace(\".json\", \"\").split(\"--\")[1] + \".\" + file.replace(\".json\", \"\").split(\"--\")[2]\n",
    "        try:\n",
    "            src_trg_set = set()\n",
    "            for src_trg_pairs in json_file[\"lineage\"]:\n",
    "                src_trg_set.add(src_trg_pairs[\"source\"])\n",
    "                src_trg_set.add(src_trg_pairs[\"target\"])\n",
    "            src_trg_set.remove(json_file[\"file_name\"])\n",
    "        except Exception as e:\n",
    "            error_json_reading[json_file[\"file_name\"]] = e\n",
    "        \n",
    "        json_file[\"content_set\"] = src_trg_set\n",
    "        json_list.append(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef51936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"error_json_reading: \", len(error_json_reading))\n",
    "print(\"Key template of each dictionary in list: \",json_list[0].keys())\n",
    "print(json_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb8455",
   "metadata": {},
   "source": [
    "### Create set of all lineage objects present in csv file for each dependent object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bcea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "# Load data\n",
    "df_dev_linage = pd.read_csv(\"databases_lineage_extracted.csv\")\n",
    "df_uat_linage = pd.read_csv(\"database_lineage_extracted_2.csv\")\n",
    "df_unioned = pd.concat([df_dev_linage, df_uat_linage], ignore_index=True)\n",
    "df_unioned\n",
    "\n",
    "subset_cols = ['Dependent_Schema', 'Dependent_Object_Name', 'Dependent_Object_Type',\n",
    "               'Depends_On_Schema', 'Depends_On_Object_Name', 'Depends_On_Object_Type']\n",
    "df = df_unioned.drop_duplicates(subset=subset_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449bd928",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_list = {}\n",
    "for (dependent_schema, dependent_object_name), group in df.groupby([\"Dependent_Schema\",\"Dependent_Object_Name\"]):\n",
    "    dependent_object_name = re.sub(r\"[^\\w\\s-]\", \"\", dependent_object_name).replace(\" \", \"_\")\n",
    "    lineage_list[dependent_schema + \".\" + dependent_object_name] = set()\n",
    "    for row in group.itertuples():\n",
    "        content = row[7] + '.' + row[8]\n",
    "        lineage_list[dependent_schema + \".\" + dependent_object_name].add(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf70d4b",
   "metadata": {},
   "source": [
    "### Analyze both data structure and find out unequal sets containing lineage objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa234dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "incorrect = []\n",
    "errors = []\n",
    "for json_item in json_list:\n",
    "    try:\n",
    "        if json_item[\"content_set\"] == lineage_list[json_item[\"file_name\"]]:\n",
    "            correct.append(json_item[\"file_name\"])\n",
    "        else:\n",
    "            incorrect.append(json_item[\"file_name\"])\n",
    "    except Exception as e:\n",
    "        errors.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bf5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"correct_jsons: \" ,len(correct), \"\\nIncorrect_jsons: \", len(incorrect), \"\\nTotal jsons processed :\", len(correct) + len(incorrect), \"\\nErrors: \", len(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for object in incorrect:\n",
    "    print(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5de3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for object in incorrect:\n",
    "#     if object == \"tmp.usp_Cobachi_Business_Hierarchy_PST\":\n",
    "#         print(True)\n",
    "#     else:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd22d12",
   "metadata": {},
   "source": [
    "## Search content from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a347a895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "depend_schema = \"\"\n",
    "dependent_object_name = \"\"\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2e38b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find item and it's lineage set in json_list read from json files.\n",
    "for item in json_list:\n",
    "    if item['file_name'] == depend_schema + '.' + dependent_object_name:\n",
    "        print(\"file_name present in json_list\\n\")\n",
    "        print(item['content_set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12be538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in lineage_list:\n",
    "    if item == depend_schema + '.' + dependent_object_name:\n",
    "        print('Dependent_object_name: ', item, \"\\n Lineage set: \", lineage_list[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d9d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_linage = pd.read_csv(\"databases_lineage_extracted.csv\")\n",
    "df_uat_linage = pd.read_csv(\"database_lineage_extracted_2.csv\")\n",
    "df_unioned = pd.concat([df_dev_linage, df_uat_linage], ignore_index=True)\n",
    "df_unioned\n",
    "\n",
    "subset_cols = ['Dependent_Schema', 'Dependent_Object_Name', 'Dependent_Object_Type',\n",
    "               'Depends_On_Schema', 'Depends_On_Object_Name', 'Depends_On_Object_Type']\n",
    "df = df_unioned.drop_duplicates(subset=subset_cols)\n",
    "df = df.query(f\"Dependent_Schema == '{depend_schema}' and Dependent_Object_Name == '{dependent_object_name}'\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_clean_sql(sql_query):\n",
    "    sql_text = str(sql_query)\n",
    "\n",
    "    sql_text = sql_text.replace('\\\\n', '\\n').replace('\\\\t', '\\t')\n",
    "\n",
    "    # Remove single-line comments (-- ...)\n",
    "    sql_text = re.sub(r'--.*', '', sql_text)\n",
    "    # Remove multi-line comments (/* ... */)\n",
    "    sql_text = re.sub(r'/\\*.*?\\*/', '', sql_text, flags=re.DOTALL)\n",
    "\n",
    "    # Replace multiple newlines with a single newline\n",
    "    sql_text = re.sub(r'\\n\\s*\\n', '\\n', sql_text)\n",
    "    # Collapse horizontal spaces (tabs/spaces) into one space\n",
    "    sql_text = re.sub(r'[ \\t]+', ' ', sql_text)\n",
    "    \n",
    "    return sql_text.strip()\n",
    "\n",
    "df_definitions = pd.concat([pd.read_csv(\"object_definitions.csv\"), pd.read_csv(\"UAT_object_definitions.csv\")], ignore_index=True)\n",
    "df_definitions = df_definitions.query(f\"Schema == '{depend_schema}' and Object == '{dependent_object_name}'\")\n",
    "df_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50542d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(robust_clean_sql(df_definitions.iloc[0,4]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
